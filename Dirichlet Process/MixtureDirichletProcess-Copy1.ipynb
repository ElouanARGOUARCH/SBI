{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617e5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch \n",
    "import pyro\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import matplotlib\n",
    "from utils import plot_2d_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95550c",
   "metadata": {},
   "source": [
    "We generate $x_1,..., x_N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4858176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 2])\n"
     ]
    }
   ],
   "source": [
    "from targets.conditional_density_estimation_target import Wave\n",
    "target = Wave()\n",
    "\n",
    "N_simulations = 500\n",
    "D_theta = target.sample_prior(N_simulations)\n",
    "D_x = target.simulate(D_theta)\n",
    "\n",
    "mu_theta = torch.zeros(1)\n",
    "sigma_theta = torch.eye(1)\n",
    "theta_prior_distribution = torch.distributions.MultivariateNormal(mu_theta, sigma_theta)\n",
    "theta0 = theta_prior_distribution.sample()\n",
    "theta0 = 0*torch.ones(1)\n",
    "\n",
    "N_observations = 1\n",
    "x0 = target.simulate(theta0.unsqueeze(0).repeat(N_observations,1))\n",
    "x = torch.cat([D_theta, D_x], dim=1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4162711",
   "metadata": {},
   "source": [
    "We suppose that the data is generated according to the following sampling scheme:\n",
    "- $w_1,...,w_K,... \\sim GEM(\\alpha)$ is a prior over mean and covariances\n",
    "- $(\\mu_1, \\Sigma_1),..., (\\mu_K,\\Sigma_K),... \\sim NIW(\\mu_0, \\lambda, \\Psi, \\nu)$ \n",
    "- $z_1,..., z_N \\sim \\sum_{k=1}^\\infty w_k \\delta_k$\n",
    "- $x_i|z_i \\sim N(mu_{z_i}, \\Sigma_{z_i})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689d48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior_parameters\n",
    "d=2\n",
    "nu = 3\n",
    "lbda = 0.01\n",
    "mu = torch.mean(x, dim=0).float()\n",
    "psi = torch.eye(d)/50\n",
    "alpha = torch.tensor(10.)\n",
    "truncation = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac91857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_assignation(x,z):\n",
    "    plt.scatter(x[:,0].numpy(), x[:,1].numpy(), c=z, cmap = matplotlib.cm.get_cmap('plasma'), alpha = .5)\n",
    "\n",
    "def compute_posterior_parameters(x): \n",
    "    empirical_mean = torch.mean(x, dim =0)\n",
    "    mu_N = (lbda*mu + x.shape[0]*empirical_mean)/(lbda + x.shape[0])\n",
    "    S = torch.cov(x.T)*(x.shape[0]-1) if x.shape[0]>=2 else torch.zeros(d)\n",
    "    temp = (empirical_mean-mu).unsqueeze(-1)\n",
    "    psi_N = psi + S + (lbda*x.shape[0]*temp@temp.T)/(lbda + x.shape[0])\n",
    "    return nu + x.shape[0], lbda + x.shape[0], mu_N, psi_N\n",
    "    \n",
    "def compute_probability(x,z,i):\n",
    "    z_i = torch.cat([z[:i], z[i+1:]], dim =0)\n",
    "    list_weight = []\n",
    "    list_evaluated_prob=[]\n",
    "    for c in torch.unique(z_i):\n",
    "        extracted = x[z==c]\n",
    "        nu_n_c, lbda_n_c, mu_n_c, psi_n_c = compute_posterior_parameters(extracted)\n",
    "        list_weight.append(extracted.shape[0]/(x.shape[0]-1+alpha))\n",
    "        list_evaluated_prob.append(torch.exp(pyro.distributions.MultivariateStudentT(nu_n_c-d+1,mu_n_c,torch.cholesky(psi_n_c*(lbda_n_c+1)/(lbda_n_c*(nu_n_c - d + 1)))).log_prob(x[i,:])))\n",
    "    list_evaluated_prob.append(torch.exp(pyro.distributions.MultivariateStudentT(nu-d+1,mu,torch.cholesky(psi*(lbda+1)/(lbda*(nu - d + 1)))).log_prob(x[i,:])))                               \n",
    "    list_weight.append(alpha/(x.shape[0]-1+alpha))\n",
    "    probs = torch.tensor(list_weight)*torch.tensor(list_evaluated_prob)\n",
    "    return probs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "342928fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(new_x,x,z):\n",
    "    list_weight = []\n",
    "    list_evaluated_prob=[]\n",
    "    for c in torch.unique(z):\n",
    "        extracted = x[z==c]\n",
    "        nu_n_c, lbda_n_c, mu_n_c, psi_n_c = compute_posterior_parameters(extracted)\n",
    "        list_weight.append(extracted.shape[0]/(x.shape[0]))\n",
    "        list_evaluated_prob.append(torch.exp(pyro.distributions.MultivariateStudentT(nu_n_c-d+1,mu_n_c,torch.cholesky(psi_n_c*(lbda_n_c+1)/(lbda_n_c*(nu_n_c - d + 1)))).log_prob(new_x)).unsqueeze(-1))\n",
    "        temp  = torch.exp(pyro.distributions.MultivariateStudentT(nu_n_c-d+1,mu_n_c,torch.cholesky(psi_n_c*(lbda_n_c+1)/(lbda_n_c*(nu_n_c - d + 1)))).log_prob(new_x))\n",
    "    probs = torch.sum(torch.tensor(list_weight).unsqueeze(0)*torch.cat(list_evaluated_prob, dim=1), dim= -1)\n",
    "    return probs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e93d7ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z =torch.zeros(x.shape[0])\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    for i in range(x.shape[0]):\n",
    "        probs = compute_probability(x,z,i)\n",
    "        temp = torch.cat([z[:i], z[i+1:]], dim =0)\n",
    "        list_z_i = torch.cat([torch.unique(temp),(torch.max(torch.unique(temp)) + 1).unsqueeze(-1)])\n",
    "        z[i] = list_z_i[torch.distributions.Categorical(probs/torch.sum(probs)).sample()]\n",
    "    print(torch.unique(z).shape)\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plot_assignation(x,z)\n",
    "    plt.show()\n",
    "    plot_2d_function(lambda samples: prob(samples,x,z),x_min =torch.min(x[:,0])-0.25,x_max = torch.max(x[:,0])+0.25, y_min = torch.min(x[:,1])-0.25, y_max = torch.max(x[:,1])+0.25, delta = 100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fbae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_function(f, x_min = -10,x_max = 10, y_min = -10, y_max = 10, delta = 200, levels = 2 , alpha = 0.7, new_figure = True):\n",
    "    if new_figure :\n",
    "        plt.figure(figsize = (10,10))\n",
    "        plt.tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    tt_x = torch.linspace(x_min, x_max, delta)\n",
    "    tt_y = torch.linspace(y_min,y_max, delta)\n",
    "    mesh = torch.cartesian_prod(tt_x, tt_y)\n",
    "    with torch.no_grad():\n",
    "        plt.contourf(tt_x,tt_y,f(mesh).numpy().reshape(delta,delta).T, levels = levels, cmap = matplotlib.cm.get_cmap('viridis'), alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b546d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
