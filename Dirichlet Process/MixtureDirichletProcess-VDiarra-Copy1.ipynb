{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617e5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pyro\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95550c",
   "metadata": {},
   "source": [
    "We generate $x_1,..., x_N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4858176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 2])\n"
     ]
    }
   ],
   "source": [
    "from targets.conditional_density_estimation_target import Wave\n",
    "target = Wave()\n",
    "\n",
    "N_simulations = 50000\n",
    "D_theta = target.sample_prior(N_simulations)\n",
    "D_x = target.simulate(D_theta)\n",
    "\n",
    "mu_theta = torch.zeros(1)\n",
    "sigma_theta = torch.eye(1)\n",
    "theta_prior_distribution = torch.distributions.MultivariateNormal(mu_theta, sigma_theta)\n",
    "theta0 = theta_prior_distribution.sample()\n",
    "theta0 = 0*torch.ones(1)\n",
    "\n",
    "N_observations = 1\n",
    "x0 = target.simulate(theta0.unsqueeze(0).repeat(N_observations,1))\n",
    "x = torch.cat([D_theta, D_x], dim=1)\n",
    "print(x.shape)\n",
    "N = x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4162711",
   "metadata": {},
   "source": [
    "We suppose that the data is generated according to the following sampling scheme:\n",
    "- $w_1,...,w_K,... \\sim GEM(\\alpha)$ is a prior over mean and covariances\n",
    "- $(\\mu_1, \\Sigma_1),..., (\\mu_K,\\Sigma_K),... \\sim NIW(\\mu_0, \\lambda, \\Psi, \\nu)$ \n",
    "- $z_1,..., z_N \\sim \\sum_{k=1}^\\infty w_k \\delta_k$\n",
    "- $x_i|z_i \\sim N(\\mu_{z_i}, \\Sigma_{z_i})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "689d48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior_parameters\n",
    "d=2\n",
    "nu = 3\n",
    "lbda = 0.01\n",
    "mu = torch.mean(x, dim=0).float()\n",
    "psi = torch.eye(d)/50\n",
    "alpha = torch.tensor(10.)\n",
    "truncation = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a6146e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_prior_parameters(num_samples):\n",
    "    sigma = torch.inverse(torch.distributions.Wishart(nu,torch.inverse(psi)).sample([num_samples]))\n",
    "    sigma = (sigma + torch.transpose(sigma, 1,2))/2\n",
    "    mean = torch.distributions.MultivariateNormal(mu,scale_tril = torch.cholesky(sigma)/(lbda**(1/2))).sample()\n",
    "    return mean, sigma\n",
    "\n",
    "def repopulate_parameters(mean, sigma):\n",
    "    _mean, _sigma = sample_prior_parameters(truncation)\n",
    "    mean = torch.cat([mean, _mean], dim = 0)\n",
    "    sigma = torch.cat([sigma, _sigma], dim = 0)\n",
    "    return mean, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac91857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def plot_assignation(x,z):\n",
    "    plt.scatter(x[:,0].numpy(), x[:,1].numpy(), c=z, cmap = matplotlib.cm.get_cmap('plasma'), alpha = .5)\n",
    "\n",
    "def log_prob(new_x,z,mean,cov):\n",
    "    unique, count = torch.unique(z, return_counts = True)\n",
    "    weights = count/z.shape[0]\n",
    "    distribution = torch.distributions.MixtureSameFamily(torch.distributions.Categorical(weights), torch.distributions.MultivariateNormal(mean, cov))\n",
    "    return distribution.log_prob(new_x)\n",
    "\n",
    "def plot_2d_function(f, x_min = -10,x_max = 10, y_min = -10, y_max = 10, delta = 50, levels = 2 , alpha = 0.7, new_figure = True):\n",
    "    if new_figure :\n",
    "        plt.figure(figsize = (10,10))\n",
    "        plt.tick_params(left = False, right = False , labelleft = False ,labelbottom = False, bottom = False)\n",
    "    tt_x = torch.linspace(x_min, x_max, delta)\n",
    "    tt_y = torch.linspace(y_min,y_max, delta)\n",
    "    mesh = torch.cartesian_prod(tt_x, tt_y)\n",
    "    with torch.no_grad():\n",
    "        plt.contourf(tt_x,tt_y,f(mesh).numpy().reshape(delta,delta).T, levels = levels, cmap = matplotlib.cm.get_cmap('viridis'), alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69c92391",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta_distribution = torch.distributions.Beta(1, alpha)\n",
    "def sample_weights(z): \n",
    "    counts = torch.unique(z, return_counts = True)[1]\n",
    "    probs = torch.cat([counts,alpha.unsqueeze(-1)], dim = -1)\n",
    "    w = torch.distributions.Dirichlet(probs).sample()\n",
    "    r = w[-1]\n",
    "    w_ = w[:-1]\n",
    "    for i in range(truncation-1):\n",
    "        v = Beta_distribution.sample()\n",
    "        w = r*v\n",
    "        r = r*(1-v)\n",
    "        w_ = torch.cat([w_,w.unsqueeze(-1)], dim = -1)\n",
    "    w_ = torch.cat([w_,r.unsqueeze(-1)], dim = -1)\n",
    "    return w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56706b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_allocation(w, x, mean, cov): \n",
    "    w_i_k = w.unsqueeze(0).repeat(x.shape[0],1)\n",
    "    p_i_k = torch.exp(torch.distributions.MultivariateNormal(mean, cov).log_prob(x.unsqueeze(1).repeat(1,w.shape[0],1)))\n",
    "    temp = p_i_k*w_i_k\n",
    "    return torch.distributions.Categorical(temp/ torch.sum(temp, dim = -1).unsqueeze(-1)).sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c32b546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equivalent_allocation(z, mean, cov):\n",
    "    unique, inverse_index = torch.unique(z, return_inverse = True)\n",
    "    new_mean = mean[unique]\n",
    "    new_cov = cov[unique]\n",
    "    return inverse_index, new_mean, new_cov\n",
    "\n",
    "def sample_parameter_posterior(z,x):\n",
    "    list_mean = []\n",
    "    list_cov = []\n",
    "    for c in torch.unique(z):\n",
    "        x_c = x[z==c]\n",
    "        N_c = x_c.shape[0]\n",
    "        empirical_mean = torch.mean(x_c, dim =0)\n",
    "        temp = (empirical_mean-mu).unsqueeze(-1)\n",
    "        cov_c = torch.inverse(torch.distributions.Wishart(nu+N_c,torch.inverse(psi + (torch.cov(x_c.T)*(N_c-1) if N_c>=2 else torch.zeros(d)) + (lbda*N_c*temp@temp.T)/(lbda + N_c))).sample())\n",
    "        cov_c = (cov_c + torch.transpose(cov_c,0,1))/2\n",
    "        mean_c = torch.distributions.MultivariateNormal((lbda*mu + N_c*empirical_mean)/(lbda + N_c), scale_tril = torch.cholesky(cov_c)/(lbda + N_c)**(1/2)).sample()\n",
    "        list_cov.append(cov_c.unsqueeze(0))\n",
    "        list_mean.append(mean_c.unsqueeze(0))\n",
    "    return torch.cat(list_mean, dim = 0), torch.cat(list_cov, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9368b604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m w \u001b[38;5;241m=\u001b[39m sample_weights(z)\n\u001b[0;32m      6\u001b[0m mean, cov \u001b[38;5;241m=\u001b[39m repopulate_parameters(mean, cov)\n\u001b[1;32m----> 7\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43msample_allocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m z, mean, cov \u001b[38;5;241m=\u001b[39m equivalent_allocation(z, mean, cov)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36msample_allocation\u001b[1;34m(w, x, mean, cov)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_allocation\u001b[39m(w, x, mean, cov): \n\u001b[0;32m      2\u001b[0m     w_i_k \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     p_i_k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultivariateNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m     temp \u001b[38;5;241m=\u001b[39m p_i_k\u001b[38;5;241m*\u001b[39mw_i_k\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mCategorical(temp\u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(temp, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msample()\n",
      "File \u001b[1;32mc:\\users\\ea264728\\pycharmprojects\\sbi\\venv\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py:208\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sample(value)\n\u001b[0;32m    207\u001b[0m diff \u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\n\u001b[1;32m--> 208\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[43m_batch_mahalanobis\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbroadcasted_scale_tril\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m half_log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbroadcasted_scale_tril\u001b[38;5;241m.\u001b[39mdiagonal(dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlog()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m+\u001b[39m M) \u001b[38;5;241m-\u001b[39m half_log_det\n",
      "File \u001b[1;32mc:\\users\\ea264728\\pycharmprojects\\sbi\\venv\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py:57\u001b[0m, in \u001b[0;36m_batch_mahalanobis\u001b[1;34m(bL, bx)\u001b[0m\n\u001b[0;32m     55\u001b[0m flat_x \u001b[38;5;241m=\u001b[39m bx\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, flat_L\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), n)  \u001b[38;5;66;03m# shape = c x b x n\u001b[39;00m\n\u001b[0;32m     56\u001b[0m flat_x_swap \u001b[38;5;241m=\u001b[39m flat_x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape = b x n x c\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m M_swap \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_triangular\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_x_swap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape = b x c\u001b[39;00m\n\u001b[0;32m     58\u001b[0m M \u001b[38;5;241m=\u001b[39m M_swap\u001b[38;5;241m.\u001b[39mt()  \u001b[38;5;66;03m# shape = c x b\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Now we revert the above reshape and permute operators.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "z = torch.randint(size = [N], high = 1)\n",
    "mean = torch.zeros(2).unsqueeze(0).repeat(1,1)\n",
    "cov = torch.eye(2).unsqueeze(0).repeat(1,1,1)\n",
    "while True:\n",
    "    w = sample_weights(z)\n",
    "    mean, cov = repopulate_parameters(mean, cov)\n",
    "    z = sample_allocation(w, x, mean, cov)\n",
    "    z, mean, cov = equivalent_allocation(z, mean, cov)\n",
    "    print(mean.shape[0])\n",
    "    mean, cov = sample_parameter_posterior(z,x)\n",
    "    clear_output(wait=True)\n",
    "    plot_2d_function(lambda samples: torch.exp(log_prob(samples,z, mean, cov)),x_min =torch.min(x[:,0])-0.25,x_max = torch.max(x[:,0])+0.25, y_min = torch.min(x[:,1])-0.25, y_max = torch.max(x[:,1])+0.25, levels = 10)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
